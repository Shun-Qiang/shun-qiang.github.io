<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <title>激活函数 | 寻梦乌托邦</title>
  <meta name="keywords" content="">
  <meta name="description" content="激活函数 | 寻梦乌托邦">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="正直 勇敢 追梦的人">
<meta property="og:type" content="website">
<meta property="og:title" content="分类">
<meta property="og:url" content="http://shun-qiang.github.io/categories/index.html">
<meta property="og:site_name" content="寻梦乌托邦">
<meta property="og:description" content="正直 勇敢 追梦的人">
<meta property="og:updated_time" content="2017-12-14T07:06:48.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分类">
<meta name="twitter:description" content="正直 勇敢 追梦的人">


<link rel="icon" href="/img/avatar-sun.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1" ></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.0.1" ></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="false">
  <input class="theme_blog_path" value="">
</div>

<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar-sun.jpg" />
</a>
<div class="author">
    <span>顺强</span>
</div>

<div class="icon">
    
</div>




<ul>
    <li><div class="all active">全部文章<small>(67)</small></div></li>
    
        
            
            <li><div data-rel="CNN">CNN<small>(23)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="Colab">Colab<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="C++">C++<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="CV">CV<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="高等数学">高等数学<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="GIT">GIT<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="HEXO">HEXO<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="SLAM">SLAM<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="NUMPY">NUMPY<small>(3)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="Linux">Linux<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="标记语言">标记语言<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="lintcode">lintcode<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="概率论">概率论<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="PYTHON">PYTHON<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="python">python<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="pytorch">pytorch<small>(3)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="算法">算法<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="数据结构">数据结构<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="NLP">NLP<small>(2)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="leetcode">leetcode<small>(16)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="Paper">Paper<small>(3)</small></div>
                
            </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    </div>
    <div><a class="about  hasFriend  site_url"  href="/about">关于</a><a style="width: 50%"  class="friends">友链</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="67">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode === 13){return false;}">
        <input id="local-search-input" class="search" type="text" placeholder="Search..." />
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none" />
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a class="color4">Binary Search</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">sort</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <nav id="title-list-nav">
        
        <a  class=""
           href="/about/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="关于我">关于我</span>
            <span class="post-date" title="2019-11-01 09:36:58">2019/11/01</span>
        </a>
        
        <a  class="CNN "
           href="/activate-function/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="激活函数">激活函数</span>
            <span class="post-date" title="2019-02-02 23:59:00">2019/02/02</span>
        </a>
        
        <a  class="CNN "
           href="/bias-variance/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="偏差和方差（bias variance）过拟合 欠拟合（underfit overfit）">偏差和方差（bias variance）过拟合 欠拟合（underfit overfit）</span>
            <span class="post-date" title="2019-02-01 23:59:00">2019/02/01</span>
        </a>
        
        <a  class="CNN "
           href="/bilinear-convtranspose/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="双线性插值和转置卷积">双线性插值和转置卷积</span>
            <span class="post-date" title="2018-03-11 23:59:00">2018/03/11</span>
        </a>
        
        <a  class="CNN "
           href="/bn/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Batch Normalization">Batch Normalization</span>
            <span class="post-date" title="2019-12-18 23:59:00">2019/12/18</span>
        </a>
        
        <a  class="Colab "
           href="/colab-offline/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Colab 防止断线">Colab 防止断线</span>
            <span class="post-date" title="2018-10-28 23:59:00">2018/10/28</span>
        </a>
        
        <a  class="CNN "
           href="/cnn/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Convolution Nerture Network">Convolution Nerture Network</span>
            <span class="post-date" title="2019-01-18 23:59:00">2019/01/18</span>
        </a>
        
        <a  class=""
           href="/convolution/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="卷积">卷积</span>
            <span class="post-date" title="2019-06-11 23:59:00">2019/06/11</span>
        </a>
        
        <a  class="C++ "
           href="/cpp/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="C++程序设计（面向对象进阶）">C++程序设计（面向对象进阶）</span>
            <span class="post-date" title="2020-02-24 23:59:00">2020/02/24</span>
        </a>
        
        <a  class="CV "
           href="/cv-task/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="CV Tasks">CV Tasks</span>
            <span class="post-date" title="2019-12-01 23:59:00">2019/12/01</span>
        </a>
        
        <a  class="CNN "
           href="/data-augmentation/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="数据增强 Data Augmentation">数据增强 Data Augmentation</span>
            <span class="post-date" title="2019-12-22 23:59:00">2019/12/22</span>
        </a>
        
        <a  class="CNN "
           href="/deep-learning-start/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="深度学习">深度学习</span>
            <span class="post-date" title="2019-02-18 23:59:00">2019/02/18</span>
        </a>
        
        <a  class="CNN "
           href="/eval/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="评估标准">评估标准</span>
            <span class="post-date" title="2019-01-20 23:59:00">2019/01/20</span>
        </a>
        
        <a  class="高等数学 "
           href="/function/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="函数的凹凸性">函数的凹凸性</span>
            <span class="post-date" title="2017-04-01 23:59:00">2017/04/01</span>
        </a>
        
        <a  class="GIT "
           href="/git-note/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Git 笔记">Git 笔记</span>
            <span class="post-date" title="2015-02-16 01:20:12">2015/02/16</span>
        </a>
        
        <a  class="HEXO "
           href="/hexo-troubleshoot/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Hexo troubleshooting">Hexo troubleshooting</span>
            <span class="post-date" title="2015-02-01 23:59:00">2015/02/01</span>
        </a>
        
        <a  class="CNN "
           href="/image-caption/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="image-caption">image-caption</span>
            <span class="post-date" title="2020-02-03 23:59:00">2020/02/03</span>
        </a>
        
        <a  class="CNN "
           href="/inception/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Inception">Inception</span>
            <span class="post-date" title="2019-12-25 23:59:00">2019/12/25</span>
        </a>
        
        <a  class="SLAM "
           href="/kalman-filter/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Kalman Filter">Kalman Filter</span>
            <span class="post-date" title="2015-04-18 23:59:00">2015/04/18</span>
        </a>
        
        <a  class="CNN "
           href="/lane-summary/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="车道线项目总结">车道线项目总结</span>
            <span class="post-date" title="2020-03-23 23:59:00">2020/03/23</span>
        </a>
        
        <a  class="CNN "
           href="/learning-rate/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="深度学习超参数">深度学习超参数</span>
            <span class="post-date" title="2019-02-21 23:59:00">2019/02/21</span>
        </a>
        
        <a  class="NUMPY "
           href="/linear-regression/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="线性回归 Linear Regression">线性回归 Linear Regression</span>
            <span class="post-date" title="2019-12-06 01:20:12">2019/12/06</span>
        </a>
        
        <a  class="Linux "
           href="/linux-note/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Linux 笔记">Linux 笔记</span>
            <span class="post-date" title="2015-01-06 01:20:12">2015/01/06</span>
        </a>
        
        <a  class="CNN "
           href="/loss-function/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="LOSS函数">LOSS函数</span>
            <span class="post-date" title="2019-03-05 23:59:00">2019/03/05</span>
        </a>
        
        <a  class="标记语言 "
           href="/markdown/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="MARKDOWN 小知识">MARKDOWN 小知识</span>
            <span class="post-date" title="2017-12-18 23:59:00">2017/12/18</span>
        </a>
        
        <a  class="lintcode "
           href="/maximum-number/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="585. Maximum Number in Mountain Sequence">585. Maximum Number in Mountain Sequence</span>
            <span class="post-date" title="2019-09-17 23:59:00">2019/09/17</span>
        </a>
        
        <a  class="CNN "
           href="/mobilenet/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="MobileNet">MobileNet</span>
            <span class="post-date" title="2019-12-13 23:59:00">2019/12/13</span>
        </a>
        
        <a  class="NUMPY "
           href="/numpy-nn/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Numpy 构建神经网络">Numpy 构建神经网络</span>
            <span class="post-date" title="2018-04-06 01:20:12">2018/04/06</span>
        </a>
        
        <a  class="NUMPY "
           href="/numpy/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Numpy">Numpy</span>
            <span class="post-date" title="2018-01-06 01:20:12">2018/01/06</span>
        </a>
        
        <a  class="CNN "
           href="/pooling/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="池化层">池化层</span>
            <span class="post-date" title="2019-10-12 23:59:00">2019/10/12</span>
        </a>
        
        <a  class="CNN "
           href="/optimization-algorithm/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="优化算法">优化算法</span>
            <span class="post-date" title="2020-03-23 23:59:00">2020/03/23</span>
        </a>
        
        <a  class="概率论 "
           href="/probability-theory/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="概率论">概率论</span>
            <span class="post-date" title="2018-03-23 23:59:00">2018/03/23</span>
        </a>
        
        <a  class="CNN "
           href="/python-logging/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Python logging 使用小贴士">Python logging 使用小贴士</span>
            <span class="post-date" title="2017-03-18 23:59:00">2017/03/18</span>
        </a>
        
        <a  class="PYTHON "
           href="/python-note/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Python 笔记">Python 笔记</span>
            <span class="post-date" title="2015-02-16 01:20:12">2015/02/16</span>
        </a>
        
        <a  class="python "
           href="/python-object/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Python之面向对象">Python之面向对象</span>
            <span class="post-date" title="2019-09-04 23:59:00">2019/09/04</span>
        </a>
        
        <a  class="pytorch "
           href="/pytorch-mutil-gpu/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Pytorch 多gpu并行训练">Pytorch 多gpu并行训练</span>
            <span class="post-date" title="2019-11-14 23:59:00">2019/11/14</span>
        </a>
        
        <a  class="pytorch "
           href="/pytorch-faq/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Pytorch 使用常见问题查询手册">Pytorch 使用常见问题查询手册</span>
            <span class="post-date" title="2019-09-18 23:59:00">2019/09/18</span>
        </a>
        
        <a  class="CNN "
           href="/receptive-field/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="感受野">感受野</span>
            <span class="post-date" title="2019-01-18 23:59:00">2019/01/18</span>
        </a>
        
        <a  class="CNN "
           href="/rethink-relu-to/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Rethinking ReLU to Train Better CNNs">Rethinking ReLU to Train Better CNNs</span>
            <span class="post-date" title="2015-02-01 23:59:00">2015/02/01</span>
        </a>
        
        <a  class="算法 "
           href="/sort-algorithm/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="排序算法">排序算法</span>
            <span class="post-date" title="2019-09-02 23:59:00">2019/09/02</span>
        </a>
        
        <a  class="数据结构 "
           href="/tree/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Tree">Tree</span>
            <span class="post-date" title="2015-04-18 23:59:00">2015/04/18</span>
        </a>
        
        <a  class="pytorch "
           href="/what-is-torchnn-53/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="torch.nn 到底是什么？">torch.nn 到底是什么？</span>
            <span class="post-date" title="2019-12-28 23:59:00">2019/12/28</span>
        </a>
        
        <a  class="NLP "
           href="/word-vector/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Efficient Estimation of Word Representations in Vector Space">Efficient Estimation of Word Representations in Vector Space</span>
            <span class="post-date" title="2019-10-21 23:59:00">2019/10/21</span>
        </a>
        
        <a  class="NLP "
           href="/word2vector/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="词向量">词向量</span>
            <span class="post-date" title="2020-02-18 23:59:00">2020/02/18</span>
        </a>
        
        <a  class="CNN "
           href="/xception/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Xception">Xception</span>
            <span class="post-date" title="2019-02-14 23:59:00">2019/02/14</span>
        </a>
        
        <a  class="CNN "
           href="/yolov2/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="YOLO9000 Better, Faster, Stronger">YOLO9000 Better, Faster, Stronger</span>
            <span class="post-date" title="2020-03-18 23:59:00">2020/03/18</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-125-valid-palindrome/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="125. Valid Palindrome">125. Valid Palindrome</span>
            <span class="post-date" title="2019-10-16 23:59:00">2019/10/16</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-162-find-peak-el/"
           data-tag="Binary Search"
           data-author="" >
            <span class="post-title" title="162. Find Peak Element">162. Find Peak Element</span>
            <span class="post-date" title="2020-01-13 23:59:00">2020/01/13</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-104-leetcode/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="104. Maximum Depth of Binary Tree">104. Maximum Depth of Binary Tree</span>
            <span class="post-date" title="2019-11-18 23:59:00">2019/11/18</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-215-kth-largest/"
           data-tag="sort"
           data-author="" >
            <span class="post-title" title="215. Kth Largest Element in an Array">215. Kth Largest Element in an Array</span>
            <span class="post-date" title="2020-04-10 01:20:12">2020/04/10</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-35-search-insert-p/"
           data-tag="Binary Search"
           data-author="" >
            <span class="post-title" title="35. Search Insert Position">35. Search Insert Position</span>
            <span class="post-date" title="2020-03-01 23:59:00">2020/03/01</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-240-search-a-2D-m-2/"
           data-tag="Binary Search"
           data-author="" >
            <span class="post-title" title="240. Search a 2D Matrix II">240. Search a 2D Matrix II</span>
            <span class="post-date" title="2019-04-03 23:59:00">2019/04/03</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-28-implement-str/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="28. Implement strStr()">28. Implement strStr()</span>
            <span class="post-date" title="2019-12-27 23:59:00">2019/12/27</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-455-assign-cookies/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="455. Assign Cookies 贪心算法">455. Assign Cookies 贪心算法</span>
            <span class="post-date" title="2019-12-11 23:59:00">2019/12/11</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-409-longest-palindrome/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="409. Longest Palindrome">409. Longest Palindrome</span>
            <span class="post-date" title="2017-11-01 23:59:00">2017/11/01</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-5-longest-palindromic-substring/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="5. Longest Palindromic Substring">5. Longest Palindromic Substring</span>
            <span class="post-date" title="2019-11-23 23:59:00">2019/11/23</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-50-pow/"
           data-tag="Binary Search"
           data-author="" >
            <span class="post-title" title="50. Pow(x, n)">50. Pow(x, n)</span>
            <span class="post-date" title="2020-04-13 23:59:00">2020/04/13</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-685-find-k-closest-elements/"
           data-tag="Binary Search"
           data-author="" >
            <span class="post-title" title="658. Find K Closest Elements">658. Find K Closest Elements</span>
            <span class="post-date" title="2020-04-12 23:59:00">2020/04/12</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-516-longest-palindrome-subsequence/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="516. Longest Palindrome Subsequence">516. Longest Palindrome Subsequence</span>
            <span class="post-date" title="2018-02-01 23:59:00">2018/02/01</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-binary-search-summary/"
           data-tag="Binary Search"
           data-author="" >
            <span class="post-title" title="Binary search 总结">Binary search 总结</span>
            <span class="post-date" title="2020-04-13 23:59:00">2020/04/13</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-74-search-a-2d-m/"
           data-tag="Binary Search"
           data-author="" >
            <span class="post-title" title="74. Search a 2D Matrix">74. Search a 2D Matrix</span>
            <span class="post-date" title="2020-04-13 23:59:00">2020/04/13</span>
        </a>
        
        <a  class="leetcode "
           href="/leetcode-leetcode-exercise/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="leetcode 刷题计划">leetcode 刷题计划</span>
            <span class="post-date" title="2019-11-18 23:59:00">2019/11/18</span>
        </a>
        
        <a  class="CNN "
           href="/paper-deeplab/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Deeplab">Deeplab</span>
            <span class="post-date" title="2019-12-23 23:59:00">2019/12/23</span>
        </a>
        
        <a  class="CNN "
           href="/paper-fcn/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="FCN">FCN</span>
            <span class="post-date" title="2019-12-24 23:59:00">2019/12/24</span>
        </a>
        
        <a  class="Paper "
           href="/paper-resnet/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="ResNet">ResNet</span>
            <span class="post-date" title="2019-12-18 23:59:00">2019/12/18</span>
        </a>
        
        <a  class="Paper "
           href="/paper-vgg/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="VGG Convolutional Neural Networks">VGG Convolutional Neural Networks</span>
            <span class="post-date" title="2020-01-15 23:59:00">2020/01/15</span>
        </a>
        
        <a  class="Paper "
           href="/paper-unet/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="UNET">UNET</span>
            <span class="post-date" title="2019-10-18 23:59:00">2019/10/18</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-activate-function" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">激活函数</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            
                <a  data-rel="CNN">CNN</a>
            
        </span>
        
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2020-04-01 13:26:21'>2019-02-02 23:59</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读:<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                评论:<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么需要激活函数"><span class="toc-text"><a href="#&#x4E3A;&#x4EC0;&#x4E48;&#x9700;&#x8981;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;" class="headerlink" title="&#x4E3A;&#x4EC0;&#x4E48;&#x9700;&#x8981;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;"></a>&#x4E3A;&#x4EC0;&#x4E48;&#x9700;&#x8981;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度消失和梯度爆炸"><span class="toc-text"><a href="#&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x548C;&#x68AF;&#x5EA6;&#x7206;&#x70B8;" class="headerlink" title="&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x548C;&#x68AF;&#x5EA6;&#x7206;&#x70B8;"></a>&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x548C;&#x68AF;&#x5EA6;&#x7206;&#x70B8;</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Loss-Cost-Object-Function"><span class="toc-text"><a href="#Loss-Cost-Object-Function" class="headerlink" title="Loss Cost Object Function"></a>Loss Cost Object Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么使用梯度下降来优化神经网络参数？"><span class="toc-text"><a href="#&#x4E3A;&#x4EC0;&#x4E48;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6765;&#x4F18;&#x5316;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x53C2;&#x6570;&#xFF1F;" class="headerlink" title="&#x4E3A;&#x4EC0;&#x4E48;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6765;&#x4F18;&#x5316;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x53C2;&#x6570;&#xFF1F;"></a>&#x4E3A;&#x4EC0;&#x4E48;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6765;&#x4F18;&#x5316;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x53C2;&#x6570;&#xFF1F;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#反向传播（用于优化神网参数）"><span class="toc-text"><a href="#&#x53CD;&#x5411;&#x4F20;&#x64AD;&#xFF08;&#x7528;&#x4E8E;&#x4F18;&#x5316;&#x795E;&#x7F51;&#x53C2;&#x6570;&#xFF09;" class="headerlink" title="&#x53CD;&#x5411;&#x4F20;&#x64AD;&#xFF08;&#x7528;&#x4E8E;&#x4F18;&#x5316;&#x795E;&#x7F51;&#x53C2;&#x6570;&#xFF09;"></a>&#x53CD;&#x5411;&#x4F20;&#x64AD;&#xFF08;&#x7528;&#x4E8E;&#x4F18;&#x5316;&#x795E;&#x7F51;&#x53C2;&#x6570;&#xFF09;</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#softmax"><span class="toc-text"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#公式-y-i-frac-e-z-i-sum-j-e-z-j"><span class="toc-text"><a href="#&#x516C;&#x5F0F;-y-i-frac-e-z-i-sum-j-e-z-j" class="headerlink" title="&#x516C;&#x5F0F; $y_{i}=\frac{e^{z_{i}}}{\sum_{j}^{}{e^{z_{j}}}}$"></a>&#x516C;&#x5F0F; $y_{i}=\frac{e^{z_{i}}}{\sum_{j}^{}{e^{z_{j}}}}$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#L-i-log-frac-e-z-i-sum-j-e-z-j"><span class="toc-text"><a href="#L-i-log-frac-e-z-i-sum-j-e-z-j" class="headerlink" title="$L_{i} = -\log(\frac{e^{z_{i}}}{\sum_{j}e^{z_j}})$"></a>$L_{i} = -\log(\frac{e^{z_{i}}}{\sum_{j}e^{z_j}})$</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Why-softmax"><span class="toc-text"><a href="#Why-softmax" class="headerlink" title="Why softmax"></a>Why softmax</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sigmoid"><span class="toc-text"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</span></a>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="为什么需要激活函数"><a href="#为什么需要激活函数" class="headerlink" title="为什么需要激活函数"></a>为什么需要激活函数</h2><p>从数学上看，神经网络是一个多层复合函数。激活函数在很早以前就被引入，其作用是保证神经网络的非线性，因为线性函数无论怎样复合结果还是线性的。<br>$$\hat y = X W_1 W_2 = X W_3$$<br>$$relu(x) = max(x,0)$$<br>为保证非线性，激活函数必须为非线性函数，但仅仅具有非线性是不够的。神经网络在本质上是一个复合函数，这会让我们思考一个问题：这个函数的建模能力有多强？即它能模拟什么样的目标函数？<br>已经证明，只要激活函数选择得当，神经元个数足够多，使用3层即包含一个隐含层的神经网络就可以实现对任何一个从输入向量到输出向量的连续映射函数的逼近，这个结论称为万能逼近（universal approximation）定理。</p>
<h2 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h2><h3 id="Loss-Cost-Object-Function"><a href="#Loss-Cost-Object-Function" class="headerlink" title="Loss Cost Object Function"></a>Loss Cost Object Function</h3><p>损失函数（Loss Function ）是定义在单个样本上的，算的是一个样本的误差。<br>代价函数（Cost Function ）是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。<br>目标函数（Object Function）定义为：最终需要优化的函数。等于经验风险+结构风险（也就是Cost Function + 正则化项）。<br>关于目标函数和代价函数的区别还有一种通俗的区别：<br>目标函数是最大化或者最小化，而代价函数是最小化</p>
<p>反向传播算法计算误差项时每一层都要乘以本层激活函数的导数。如果激活函数导数的绝对值值小于1，多次连乘之后误差项很快会衰减到接近于0，参数的梯度值由误差项计算得到，从而导致前面层的权重梯度接近于0，参数没有得到有效更新，这称为梯度消失问题。与之相反的是梯度爆炸问题，如果激活函数导数的绝对大于1，多次乘积之后权重值会趋向于非常大的数，这称为梯度爆炸。<br>例如 Sigmoid导数的取值范围在0-0.25之间，而我们初始化的网络权值通常都小于1，因此，当层数增多时，小于0的值不断相乘，最后就导致梯度消失的情况出现。同理，梯度爆炸的问题也就很明显了，就是当权值$|w|$过大时，导致$|\sigma’(z)w| &gt; 1$ ，最后大于1的值不断相乘，就会产生梯度爆炸。</p>
<h3 id="为什么使用梯度下降来优化神经网络参数？"><a href="#为什么使用梯度下降来优化神经网络参数？" class="headerlink" title="为什么使用梯度下降来优化神经网络参数？"></a>为什么使用梯度下降来优化神经网络参数？</h3><p>方向导数的本质是一个数值，简单来说其定义为： 一个函数沿指定方向的变化率。<br>$\frac{\partial f }{\partial l} = \frac{\partial f }{ \partial x} cos\alpha + \frac{\partial f}{\partial y} sin\alpha $<br>梯度与方向导数是有本质区别的，梯度其实是一个向量，其定义为：一个函数对于其自变量分别求偏导数，这些偏导数所组成的向量就是函数的梯度。<br>$grad f(x,y) = \frac{\partial f}{\partial x} i + \frac{\partial f}{\partial y} j$<br>梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以)。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是解析解。</p>
<h3 id="反向传播（用于优化神网参数）"><a href="#反向传播（用于优化神网参数）" class="headerlink" title="反向传播（用于优化神网参数）"></a>反向传播（用于优化神网参数）</h3><p>根据损失函数计算的误差通过反向传播的方式，指导深度网络参数的更新优化。通过定义损失函数，然后通过计算网络真实输出和真实标签之间的误差，得到网络的损失值：loss；<br>最后通过loss.backward()完成误差的反向传播，通过pytorch的内在机制完成自动求导得到每个参数的梯度。需要注意，在机器学习或者深度学习中，我们需要通过修改参数使得损失函数最小化或最大化，一般是通过梯度进行网络模型的参数更新，通过loss的计算和误差反向传播，我们得到网络中，每个参数的梯度值，后面我们再通过优化算法进行网络参数优化更新。在更新网络参数时，我们需要选择一种调整模型参数更新的策略，即优化算法。在pytorch中，torch.optim是一个实现各种优化算法的包，可以直接通过这个包进行调用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Backpropagation, an abbreviation for “backward propagation of errors”, is a common method of training artificial neural networks used in conjunction with an optimization method such as gradient descent. The method calculates the gradient of a loss function with respect to all the weights in the network. The gradient is fed to the optimization method which in turn uses it to update the weights, in an attempt to minimize the loss function.</span><br></pre></td></tr></table></figure></p>
<p>采取反向传播的原因：首先，深层网络由许多线性层和非线性层堆叠而来，每一层非线性层都可以视为是一个非线性函数(非线性来自于非线性激活函数），因此整个深度网络可以视为是一个复合的非线性多元函数。<br>我们最终的目的是希望这个非线性函数很好的完成输入到输出之间的映射，也就是找到让损失函数取得极小值。所以最终的问题就变成了一个寻找函数最小值的问题，在数学上，很自然的就会想到使用梯度下降来解决。</p>
<h1 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h1><p>softmax用于多分类过程中，它将多个神经元的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类。<br>更形象的如下图：<br><img src="https://shun-qiang.github.io/img/softmax.jpg" alt=""></p>
<h2 id="公式-y-i-frac-e-z-i-sum-j-e-z-j"><a href="#公式-y-i-frac-e-z-i-sum-j-e-z-j" class="headerlink" title="公式 $y_{i}=\frac{e^{z_{i}}}{\sum_{j}^{}{e^{z_{j}}}}$"></a>公式 $y_{i}=\frac{e^{z_{i}}}{\sum_{j}^{}{e^{z_{j}}}}$</h2><p>在神经网络的计算当中，我们经常需要计算按照神经网络的正向传播计算的分数S1，和按照正确标注计算的分数S2，之间的差距，计算Loss，才能应用反向传播。<br>Loss定义为交叉熵, NLL： </p>
<h2 id="L-i-log-frac-e-z-i-sum-j-e-z-j"><a href="#L-i-log-frac-e-z-i-sum-j-e-z-j" class="headerlink" title="$L_{i} = -\log(\frac{e^{z_{i}}}{\sum_{j}e^{z_j}})$"></a>$L_{i} = -\log(\frac{e^{z_{i}}}{\sum_{j}e^{z_j}})$</h2><p>输出层我们一般选用softmax作为激活函数</p>
<h3 id="Why-softmax"><a href="#Why-softmax" class="headerlink" title="Why softmax"></a>Why softmax</h3><ol>
<li>计算求导上非常方便</li>
<li>softmax函数值表示数据正确分类的值，它占的比重越大，这个样本的loss也就越小</li>
</ol>
<p>softmax 回归分析 scratch version<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torchvision.datasets.mnist</span><br><span class="line">PATH = Path(<span class="string">"..."</span>)</span><br><span class="line"><span class="keyword">with</span> gzip.open(PATH.as_posix(), <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=<span class="string">"latin-1"</span>)</span><br><span class="line">pyplot.imshow(x_train[<span class="number">0</span>].reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">"gray"</span>)</span><br><span class="line">pyplot.show() <span class="comment"># 显示图像</span></span><br><span class="line"></span><br><span class="line">x_train, y_train, x_valid, y_valid = map(</span><br><span class="line">    torch.tensor, (x_train, y_train, x_valid, y_valid))</span><br><span class="line">n, chhh = x_train.shape</span><br><span class="line">x_train, x_train.shape, y_train.min(), y_train.max()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">weights = torch.randn(<span class="number">784</span>, <span class="number">10</span>) / math.sqrt(<span class="number">784</span>)</span><br><span class="line">weights.requires_grad_()</span><br><span class="line">bias = torch.zeros(<span class="number">10</span>, requires_grad=<span class="keyword">True</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x - x.exp().sum(<span class="number">-1</span>).log().unsqueeze(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(xb)</span>:</span></span><br><span class="line">    <span class="string">"""model</span></span><br><span class="line"><span class="string">    the @ stands for the dot product operation</span></span><br><span class="line"><span class="string">    :param xb: input</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> log_softmax(xb @ weights + bias)</span><br><span class="line">bs = <span class="number">64</span>  <span class="comment"># batch size</span></span><br><span class="line"></span><br><span class="line">xb = x_train[<span class="number">0</span>:bs]  <span class="comment"># a mini-batch from x</span></span><br><span class="line">preds = model(xb)  <span class="comment"># predictions</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nll</span><span class="params">(input, target)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> -input[range(target.shape[<span class="number">0</span>]), target].mean()</span><br><span class="line">loss_func = nll</span><br><span class="line">yb = y_train[<span class="number">0</span>:bs]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(out, yb)</span>:</span></span><br><span class="line">    preds = torch.argmax(out, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> (preds == yb).float().mean()</span><br><span class="line">print(accuracy(preds, yb))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> IPython.core.debugger <span class="keyword">import</span> set_trace</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.5</span>  <span class="comment"># learning rate</span></span><br><span class="line">epochs = <span class="number">2</span>  <span class="comment"># how many epochs to train for</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range((n - <span class="number">1</span>) // bs + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># set_trace()</span></span><br><span class="line">        <span class="keyword">if</span> i==<span class="number">781</span>:</span><br><span class="line">            print(<span class="string">""</span>)</span><br><span class="line">        start_i = i * bs</span><br><span class="line">        end_i = start_i + bs</span><br><span class="line">        xb = x_train[start_i:end_i]</span><br><span class="line">        yb = y_train[start_i:end_i]</span><br><span class="line">        pred = model(xb)</span><br><span class="line">        loss = loss_func(pred, yb)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            weights -= weights.grad * lr</span><br><span class="line">            bias -= bias.grad * lr</span><br><span class="line">            weights.grad.zero_()</span><br><span class="line">            bias.grad.zero_()</span><br><span class="line">    print(loss,accuracy(pred, yb))</span><br><span class="line">print(loss_func(model(xb), yb), accuracy(model(xb), yb))</span><br></pre></td></tr></table></figure></p>
<h1 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h1><p>Sigmoid 是一个可微的有界函数，在各点均有非负的导数。当 x→∞ 时，S(x)→1；当 x→−∞ 时，S(x)→0。常用于二元分类（Binary Classification）问题，以及神经网络的激活函数（Activation Function）（把线性的输入转换为非线性的输出）<br>其实logistic函数也就是经常说的sigmoid函数，它的几何形状也就是一条sigmoid曲线（S型曲线）。其导数的小于等于0.25<br>在二元分类的情况下，Softmax 退化为了 Sigmoid。<br>$$<br>\sigma(x) = \frac{1}{(1+e^{-x})}<br>$$<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    sigmoid激活函数</span></span><br><span class="line"><span class="string">    :param x: 输入</span></span><br><span class="line"><span class="string">    :return: sigmoid(x)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-x))</span><br></pre></td></tr></table></figure></p>
<p>参考资料：<br>sigmoid函数图像：<br><img src="https://shun-qiang.github.io/img/sigmoid.jpg" alt=""></p>
<p>常用的激活函数以及相应的导数：<br><img src="https://shun-qiang.github.io/img/common-activate-function.jpg" alt=""></p>
<p>梯度下降：<br><a href="https://www.jianshu.com/p/c7e642877b0e" target="_blank" rel="noopener">https://www.jianshu.com/p/c7e642877b0e</a></p>
<p>方向导数与梯度的关系：<br><a href="https://blog.csdn.net/weixin_40752830/article/details/90232461" target="_blank" rel="noopener">https://blog.csdn.net/weixin_40752830/article/details/90232461</a><br><a href="http://netedu.xauat.edu.cn/jpkc/netedu/jpkc/gdsx/homepage/5jxsd/51/513/5308/530807.htm" target="_blank" rel="noopener">http://netedu.xauat.edu.cn/jpkc/netedu/jpkc/gdsx/homepage/5jxsd/51/513/5308/530807.htm</a><br>Understanding the backward pass through Batch Normalization Layer<br><a href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" target="_blank" rel="noopener">https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html</a><br><a href="http://cs231n.github.io/optimization-2/#sigmoid" target="_blank" rel="noopener">http://cs231n.github.io/optimization-2/#sigmoid</a></p>

      
       <hr><span style="font-style: italic;color: gray;"> 请多多指教。 </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>


<div class="article_copyright">
    <p><span class="copy-title">文章标题:</span>激活函数</p>
    
    <p><span class="copy-title">本文作者:</span><a  title="顺强">顺强</a></p>
    <p><span class="copy-title">发布时间:</span>2019-02-02, 23:59:00</p>
    <span class="copy-title">原始链接:</span><a class="post-url" href="/activate-function/" title="激活函数">http://shun-qiang.github.io/activate-function/</a>
    <p>
        <span class="copy-title">版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>



    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: '84f77e333f2e54aee8e3',
            clientSecret: '9b89a9d1c0f55413c892dceedee0274ce40f34cf',
            repo: 'shun-qiang.github.io',
            owner: 'Shun-Qiang',
            admin: ['Shun-Qiang'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('10',10)
        })
        gitalk.render('comments')
    })
</script>




    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<input type="hidden" id="MathJax-js"
        value="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</input>
    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2020 SHUNQIANG</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" ></a>

    </div>
</div>
<div class="acParent"></div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</body>
<script src="/js/jquery.pjax.js?v=1.0.1" ></script>

<script src="/js/script.js?v=1.0.1" ></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#Binary Search','#sort',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        
        $('pre code').each(function(){
            var lines = $(this).text().split('\n').length - 1, widther='';
            if (lines>99) {
                widther = 'widther'
            }
            var $numbering = $('<ul/>').addClass('pre-numbering ' + widther).attr("unselectable","on");
            $(this).addClass('has-numbering ' + widther)
                    .parent()
                    .append($numbering);
            for(var i=1;i<=lines;i++){
                $numbering.append($('<li/>').text(i));
            }
        });
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
        /* 渲染*/
        function HTMLDecode(text) {
            var temp = document.createElement("div");
            temp.innerHTML = text;
            var output = temp.innerText || temp.textContent;
            temp = null;
            return output;
        }
        if (window.mermaid){
            window.mermaid = null
        }
        $.getScript("//cdn.jsdelivr.net/npm/mermaid@8.4.2/dist/mermaid.min.js", function () {
            var mermaidOptions = JSON.parse(HTMLDecode("{&#34;theme&#34;:&#34;default&#34;,&#34;startOnLoad&#34;:true,&#34;flowchart&#34;:{&#34;useMaxWidth&#34;:true,&#34;htmlLabels&#34;:true}}"))
            if (window.mermaid) {
                mermaid.initialize(mermaidOptions)
                mermaid.contentLoaded()
            }
        })
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<style>
    pre{
        position: relative;
        margin-bottom: 24px;
        border-radius: 10px;
        border: 1px solid #e2dede;
        background: #FFF;
        overflow: hidden;
    }
    code.has-numbering{
        margin-left: 30px;
    }
    code.has-numbering.widther{
        margin-left: 35px;
    }
    .pre-numbering{
        margin: 0px;
        position: absolute;
        top: 0;
        left: 0;
        width: 20px;
        padding: 0.5em 3px 0.7em 5px;
        border-right: 1px solid #C3CCD0;
        text-align: right;
        color: #AAA;
        background-color: #fafafa;
    }
    .pre-numbering.widther {
        width: 35px;
    }
</style>

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.3;
        background: url("https://i.loli.net/2019/07/22/5d3521411f3f169375.png");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    

    
</style>







</html>
